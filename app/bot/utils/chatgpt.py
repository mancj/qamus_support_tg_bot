from typing import Optional, List, Dict
import logging
import json
from pathlib import Path

from openai import AsyncOpenAI
from openai.types.chat import ChatCompletionMessageParam

from app.config import OpenAIConfig


logger = logging.getLogger(__name__)


def load_knowledge_base(file_path: str) -> List[Dict[str, str]]:
    """
    Load knowledge base from JSON file.

    :param file_path: Path to the JSON file with QA pairs.
    :return: List of QA pairs.
    """
    try:
        path = Path(file_path)
        if not path.exists():
            logger.warning(f"Knowledge base file not found: {file_path}")
            return []

        with open(path, "r", encoding="utf-8") as f:
            knowledge_base = json.load(f)

        logger.info(f"Loaded {len(knowledge_base)} entries from knowledge base")
        return knowledge_base

    except Exception as e:
        logger.error(f"Error loading knowledge base: {e}")
        return []


class ChatGPTService:
    """
    Service for interacting with OpenAI ChatGPT API.

    Attributes:
    - client (AsyncOpenAI): The async OpenAI client.
    - model (str): The model to use for completions.
    - knowledge_base (List[Dict[str, str]]): QA knowledge base.
    """

    def __init__(self, config: OpenAIConfig):
        """
        Initialize the ChatGPT service.

        :param config: OpenAI configuration.
        """
        self.client = AsyncOpenAI(api_key=config.API_KEY)
        self.model = config.MODEL
        self.knowledge_base: List[Dict[str, str]] = []
        logger.info(f"ChatGPT service initialized with model: {self.model}")

    def set_knowledge_base(self, knowledge_base: List[Dict[str, str]]) -> None:
        """
        Set the knowledge base for the ChatGPT service.

        :param knowledge_base: List of QA pairs in format [{"question": "Q", "answer": "A"}, ...]
        """
        self.knowledge_base = knowledge_base
        logger.info(f"Knowledge base updated with {len(knowledge_base)} entries")

    def _build_system_prompt(self) -> str:
        """
        Build the system prompt with knowledge base.

        :return: System prompt string.
        """
        base_prompt = (
            "Ð¢Ñ‹ - Ð´Ñ€ÑƒÐ¶ÐµÐ»ÑŽÐ±Ð½Ñ‹Ð¹ Ð°ÑÑÐ¸ÑÑ‚ÐµÐ½Ñ‚ ÑÐ»ÑƒÐ¶Ð±Ñ‹ Ð¿Ð¾Ð´Ð´ÐµÑ€Ð¶ÐºÐ¸. "
            "Ð¢Ð²Ð¾Ñ Ð·Ð°Ð´Ð°Ñ‡Ð° - Ð¿Ð¾Ð¼Ð¾Ð³Ð°Ñ‚ÑŒ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»ÑÐ¼, Ð¾Ñ‚Ð²ÐµÑ‡Ð°Ñ Ð½Ð° Ð¸Ñ… Ð²Ð¾Ð¿Ñ€Ð¾ÑÑ‹ ÐµÑÑ‚ÐµÑÑ‚Ð²ÐµÐ½Ð½Ð¾ Ð¸ Ð¿Ð¾-Ñ‡ÐµÐ»Ð¾Ð²ÐµÑ‡ÐµÑÐºÐ¸.\n\n"
            "Ð£ Ñ‚ÐµÐ±Ñ ÐµÑÑ‚ÑŒ Ð±Ð°Ð·Ð° Ð·Ð½Ð°Ð½Ð¸Ð¹ - Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐ¹ ÐµÑ‘ ÐºÐ°Ðº Ð¡ÐŸÐ ÐÐ’ÐžÐ§ÐÐ˜Ðš Ð´Ð»Ñ Ð¾Ñ‚Ð²ÐµÑ‚Ð¾Ð². "
            "Ð°Ð´Ð°Ð¿Ñ‚Ð¸Ñ€ÑƒÐ¹ Ð¿Ð¾Ð´ ÐºÐ¾Ð½ÐºÑ€ÐµÑ‚Ð½Ñ‹Ð¹ Ð²Ð¾Ð¿Ñ€Ð¾Ñ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»Ñ, Ð´Ð¾Ð±Ð°Ð²ÑŒ ÑÐ¼Ð¿Ð°Ñ‚Ð¸Ð¸ Ð¸ Ð´Ñ€ÑƒÐ¶ÐµÐ»ÑŽÐ±Ð¸Ñ.\n\n"
            "Ð’ÐÐ–ÐÐ«Ð• ÐŸÐ ÐÐ’Ð˜Ð›Ð:\n"
            "1. Ð•ÑÐ»Ð¸ Ð²Ð¾Ð¿Ñ€Ð¾Ñ ÑÐ²ÑÐ·Ð°Ð½ Ñ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸ÐµÐ¹ Ð¸Ð· Ð±Ð°Ð·Ñ‹ Ð·Ð½Ð°Ð½Ð¸Ð¹ - Ð´Ð°Ð¹ ÐµÑÑ‚ÐµÑÑ‚Ð²ÐµÐ½Ð½Ñ‹Ð¹ Ð¾Ñ‚Ð²ÐµÑ‚\n"
            "2. Ð•ÑÐ»Ð¸ Ð’ÐžÐŸÐ ÐžÐ¡Ð ÐÐ•Ð¢ Ð² Ð±Ð°Ð·Ðµ Ð·Ð½Ð°Ð½Ð¸Ð¹ - Ð¾Ñ‚Ð²ÐµÑ‚ÑŒ Ð¢ÐžÐ›Ð¬ÐšÐž ÑÐ»Ð¾Ð²Ð¾Ð¼: NO_ANSWER\n"
            "3. ÐÐ• Ð¿Ñ€Ð¸Ð´ÑƒÐ¼Ñ‹Ð²Ð°Ð¹ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸ÑŽ, ÐºÐ¾Ñ‚Ð¾Ñ€Ð¾Ð¹ Ð½ÐµÑ‚ Ð² Ð±Ð°Ð·Ðµ Ð·Ð½Ð°Ð½Ð¸Ð¹\n"
            "4. Ð‘ÑƒÐ´ÑŒ ÐºÑ€Ð°Ñ‚ÐºÐ¸Ð¼, Ð½Ð¾ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚Ð¸Ð²Ð½Ñ‹Ð¼ (2-4 Ð¿Ñ€ÐµÐ´Ð»Ð¾Ð¶ÐµÐ½Ð¸Ñ)\n"
        )

        if self.knowledge_base:
            kb_text = "\n\nðŸ“š Ð‘ÐÐ—Ð Ð—ÐÐÐÐ˜Ð™ (ÑÐ¿Ñ€Ð°Ð²Ð¾Ñ‡Ð½Ð°Ñ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸Ñ):\n"
            for i, qa in enumerate(self.knowledge_base, 1):
                kb_text += f"\n{i}. Ð¢ÐµÐ¼Ð°: {qa['question']}\n   Ð˜Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸Ñ: {qa['answer']}\n"
            base_prompt += kb_text

        return base_prompt

    async def generate_response(
        self,
        user_message: str,
        conversation_history: Optional[List[ChatCompletionMessageParam]] = None,
    ) -> str:
        """
        Generate a response to user message using ChatGPT.

        :param user_message: The user's message.
        :param conversation_history: Optional conversation history.
        :return: Generated response.
        """
        try:
            messages: List[ChatCompletionMessageParam] = [
                {"role": "system", "content": self._build_system_prompt()}
            ]

            # Add conversation history if provided
            if conversation_history:
                messages.extend(conversation_history)

            # Add current user message
            messages.append({"role": "user", "content": user_message})

            logger.info(f"Generating response for message: {user_message[:50]}...")

            response = await self.client.chat.completions.create(
                model=self.model,
                messages=messages,
                temperature=0.9,
                max_tokens=500,
            )

            generated_text = response.choices[0].message.content or ""
            logger.info(f"Response generated: {generated_text[:50]}...")

            return generated_text

        except Exception as e:
            logger.error(f"Error generating ChatGPT response: {e}")
            raise

    async def generate_response_with_context(
        self,
        user_message: str,
        previous_messages: Optional[List[Dict[str, str]]] = None,
    ) -> str:
        """
        Generate a response with simplified conversation context.

        :param user_message: The user's message.
        :param previous_messages: List of previous messages in format [{"role": "user/assistant", "content": "..."}, ...]
        :return: Generated response.
        """
        conversation_history: List[ChatCompletionMessageParam] = []

        if previous_messages:
            for msg in previous_messages:
                if msg["role"] == "user":
                    conversation_history.append({"role": "user", "content": msg["content"]})
                elif msg["role"] == "assistant":
                    conversation_history.append({"role": "assistant", "content": msg["content"]})

        return await self.generate_response(user_message, conversation_history)

    def has_valid_answer(self, response: str) -> bool:
        """
        Check if ChatGPT provided a valid answer (not NO_ANSWER).

        :param response: The response from ChatGPT.
        :return: True if valid answer, False otherwise.
        """
        return response.strip() != "NO_ANSWER" and len(response.strip()) > 0
